{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\dongy\\Sentiment Analysis on Movie Reviews\\dataset\\train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv(r'C:\\Users\\dongy\\Sentiment Analysis on Movie Reviews\\dataset\\test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>20181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>12594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>12508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>4531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than</th>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credits</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>until</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niro</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ways</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stunning</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energetic</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substance</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powerful</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slasher</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickly</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>century</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheap</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60s</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efforts</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaves</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loved</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>told</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brilliant</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           frequency\n",
       "the            20181\n",
       "and            12594\n",
       "of             12508\n",
       "to              9142\n",
       "in              5658\n",
       "is              5322\n",
       "it              4857\n",
       "that            4531\n",
       "as              3366\n",
       "with            2972\n",
       "its             2953\n",
       "for             2880\n",
       "this            2529\n",
       "film            2486\n",
       "an              2448\n",
       "movie           2333\n",
       "but             2001\n",
       "be              1935\n",
       "on              1896\n",
       "you             1832\n",
       "by              1733\n",
       "more            1642\n",
       "his             1608\n",
       "than            1566\n",
       "not             1495\n",
       "like            1428\n",
       "at              1384\n",
       "about           1358\n",
       "one             1335\n",
       "from            1320\n",
       "...              ...\n",
       "credits           70\n",
       "until             70\n",
       "niro              70\n",
       "ways              70\n",
       "post              69\n",
       "chemistry         69\n",
       "stunning          69\n",
       "alone             69\n",
       "energetic         69\n",
       "substance         69\n",
       "powerful          69\n",
       "america           69\n",
       "fashion           69\n",
       "surprise          68\n",
       "slasher           68\n",
       "group             68\n",
       "quickly           68\n",
       "took              68\n",
       "century           68\n",
       "cheap             68\n",
       "60s               68\n",
       "efforts           67\n",
       "today             67\n",
       "leaves            67\n",
       "loved             67\n",
       "told              67\n",
       "sports            67\n",
       "brilliant         67\n",
       "change            67\n",
       "vision            67\n",
       "\n",
       "[744 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word = set(stopwords.words('english')) \n",
    "word_vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word', min_df=0.001)\n",
    "sparse_matrix = word_vectorizer.fit_transform(df_test['Phrase'])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "freq = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "freq.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16a14c44358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAFuCAYAAADanI/3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGWmQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16a16483940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization of data set\n",
    "a = df_train.Sentiment.value_counts()\n",
    "a = pd.DataFrame(a)\n",
    "a['Rating'] = a.index\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(y='Sentiment', x='Rating', data=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we make text lower case and leave only letters from a-z and digits\n",
    "df_train['Phrase'] = df_train['Phrase'].str.lower()\n",
    "df_train['Phrase'] = df_train['Phrase'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "df_test['Phrase'] = df_test['Phrase'].str.lower()\n",
    "df_test['Phrase'] = df_test['Phrase'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 48)\n",
      "(66292, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.Phrase\n",
    "y_train = df_train.Sentiment\n",
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(X_train.values)\n",
    "X_test = df_test.Phrase\n",
    "X_train = tokenize.texts_to_sequences(X_train)\n",
    "X_test = tokenize.texts_to_sequences(X_test)\n",
    "max_lenght = max([len(s.split()) for s in df_train['Phrase']])\n",
    "X_train = pad_sequences(X_train, max_lenght)\n",
    "X_test = pad_sequences(X_test, max_lenght)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I choose to build 3 hidden layers\n",
    "EMBEDDING_DIM = 100\n",
    "unknown = len(tokenize.word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_lenght))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2 ))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 48, 100)           1637800   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,755,693\n",
      "Trainable params: 1,755,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n",
      "(156060, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "type(X_train)\n",
    "type(y_train)\n",
    "y_train = y_train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(156060, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)\n",
    "y_train.shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156060 samples\n",
      "Epoch 1/7\n",
      "   128/156060 [..............................] - ETA: 34:19"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal:  Blas GEMM launch failed : a.shape=(128, 128), b.shape=(128, 512), m=128, n=512, k=128\n\t [[{{node sequential/lstm/while/body/_1/MatMul_1}}]]\n\t [[Reshape_6/_34]]\n  (1) Internal:  Blas GEMM launch failed : a.shape=(128, 128), b.shape=(128, 512), m=128, n=512, k=128\n\t [[{{node sequential/lstm/while/body/_1/MatMul_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_2912]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b67dfd5e8a4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal:  Blas GEMM launch failed : a.shape=(128, 128), b.shape=(128, 512), m=128, n=512, k=128\n\t [[{{node sequential/lstm/while/body/_1/MatMul_1}}]]\n\t [[Reshape_6/_34]]\n  (1) Internal:  Blas GEMM launch failed : a.shape=(128, 128), b.shape=(128, 512), m=128, n=512, k=128\n\t [[{{node sequential/lstm/while/body/_1/MatMul_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_2912]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "夏阳/街道/外/青松/公路/6999/弄仁恒/运杰/河滨/花园/118/#/801\n"
     ]
    }
   ],
   "source": [
    "text = '夏阳街道外青松公路6999弄仁恒运杰河滨花园118#801'\n",
    "text_cut = jieba.cut(text, cut_all=False)\n",
    "print('/'.join(text_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
