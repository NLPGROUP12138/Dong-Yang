{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai with HuggingFace ğŸ¤—Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç®€ä»‹:NLPä¸­è¿ç§»å­¦ä¹ çš„æ•…äº‹**\n",
    "\n",
    "åœ¨2018å¹´åˆï¼ŒJeremy Howard (fast.aiçš„è”åˆåˆ›å§‹äºº)å’ŒSebastian Ruderä»‹ç»äº†ç”¨äºæ–‡æœ¬åˆ†ç±»çš„é€šç”¨è¯­è¨€æ¨¡å‹å¾®è°ƒ(ULMFiT)æ–¹æ³•ã€‚ULMFiTæ˜¯ç¬¬ä¸€ä¸ªåº”ç”¨äºNLPçš„è¿ç§»å­¦ä¹ æ–¹æ³•ã€‚å…¶ç»“æœæ˜¯ï¼Œé™¤äº†æ˜¾è‘—ä¼˜äºè®¸å¤šæœ€å…ˆè¿›çš„ä»»åŠ¡å¤–ï¼Œå®ƒè¿˜å…è®¸ä»…ä½¿ç”¨100ä¸ªæ ‡è®°çš„ç¤ºä¾‹æ¥åŒ¹é…ç›¸å½“äºåœ¨100Ã—æ›´å¤šæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "\n",
    "\n",
    "æˆ‘ç¬¬ä¸€æ¬¡å¬è¯´ULMFiTæ˜¯åœ¨ä¸€æ¬¡æ–‹æˆ’æœŸé—´ã€‚è¿™é—¨è¯¾æ˜¯æ°é‡Œç±³Â·éœåå¾·å¼€çš„ã€‚ä»–æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨å‡ è¡Œä»£ç å®ç°å®Œæ•´çš„ULMFitæ–¹æ³•ï¼Œè¿™è¦æ„Ÿè°¢fastaiåº“ã€‚åœ¨æ¼”ç¤ºä¸­ï¼Œä»–ä½¿ç”¨äº†åœ¨Wikitext-103ä¸Šé¢„å…ˆè®­ç»ƒçš„AWD-LSTMç¥ç»ç½‘ç»œï¼Œå¹¶è¿…é€Ÿè·å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ä»–è¿˜è§£é‡Šäº†å…³é”®çš„æŠ€æœ¯â€”â€”åœ¨ULMFiTä¸­ä¹Ÿæœ‰æ¼”ç¤ºâ€”â€”æ¥å¾®è°ƒæ¨¡å‹ï¼Œå¦‚åŒºåˆ†å­¦ä¹ é€Ÿç‡ã€é€æ­¥è§£å†»æˆ–å€¾æ–œä¸‰è§’å½¢å­¦ä¹ é€Ÿç‡ã€‚\n",
    "\n",
    "\n",
    "\n",
    "è‡ªä»ULMFiTçš„å¼•å…¥ï¼Œè½¬ç§»å­¦ä¹ åœ¨NLPä¸­å˜å¾—éå¸¸æµè¡Œï¼Œç„¶è€Œè°·æ­Œ(BERT, Transformer-XL, XLNet)ã€Facebook (RoBERTa, XLM)ç”šè‡³OpenAI (GPT, GPT-2)å¼€å§‹åœ¨éå¸¸å¤§çš„æ–™åº“ä¸Šå¯¹è‡ªå·±çš„æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒã€‚è¿™ä¸€æ¬¡ï¼Œä»–ä»¬æ²¡æœ‰ä½¿ç”¨AWD-LSTMç¥ç»ç½‘ç»œï¼Œè€Œæ˜¯ä½¿ç”¨äº†ä¸€ä¸ªæ›´å¼ºå¤§çš„åŸºäºTransformerçš„æ¶æ„(cf. Attention is all you need)ã€‚\n",
    "\n",
    "\n",
    "\n",
    "å°½ç®¡è¿™äº›æ¨¡å‹åŠŸèƒ½å¼ºå¤§ï¼Œä½†æ˜¯fastaiå¹¶æ²¡æœ‰é›†æˆæ‰€æœ‰çš„æ¨¡å‹ã€‚å¹¸è¿çš„æ˜¯,HuggingFaceğŸ¤—éƒ½çŸ¥é“Transformeråº“åˆ›å»ºçš„ã€‚ä»¥å‰è¢«ç§°ä¸ºpytorch-transformeræˆ–pytorch- pretraining - BERTï¼Œè¿™ä¸ªåº“æ±‡é›†äº†40å¤šä¸ªæœ€å…ˆè¿›çš„é¢„åŸ¹è®­çš„NLPæ¨¡å‹(BERT, GPT-2, RoBERTa, CTRLâ€¦)ã€‚è¯¥å®ç°æä¾›äº†ä¸€äº›æœ‰è¶£çš„é™„åŠ å®ç”¨ç¨‹åºï¼Œå¦‚è®°å·èµ‹äºˆå™¨ã€ä¼˜åŒ–å™¨æˆ–è°ƒåº¦å™¨ã€‚\n",
    "\n",
    "\n",
    "\n",
    "Transformeråº“å¯ä»¥è‡ªç»™è‡ªè¶³ï¼Œä½†å°†å…¶æ•´åˆåˆ°fastaiåº“ä¸­ï¼Œå¯ä»¥æä¾›æ›´ç®€å•çš„å®ç°ï¼Œå¹¶ä¸åŠŸèƒ½å¼ºå¤§çš„fastaiå·¥å…·å…¼å®¹ï¼Œå¦‚åŒºåˆ†å­¦ä¹ é€Ÿç‡ã€é€æ­¥è§£å‹æˆ–å€¾æ–œä¸‰è§’å½¢å­¦ä¹ é€Ÿç‡ã€‚è¿™é‡Œçš„è¦ç‚¹æ˜¯å…è®¸éNLPä¸“å®¶è½»æ¾è·å¾—æœ€æ–°çš„ç»“æœï¼Œå› æ­¤â€œè®©NLPä¸å†é…·â€ã€‚\n",
    "\n",
    "å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒHuggingFace transformeråº“åœ¨fastaiçš„é›†æˆå·²ç»åœ¨ä»¥ä¸‹æ–¹é¢è¿›è¡Œäº†æ¼”ç¤º:\n",
    "\n",
    "Keita Kuritaçš„æ–‡ç« æ˜¯ç”¨fastaiå¾®è°ƒBERTçš„æ•™ç¨‹ï¼Œä½¿pytorch_pretrained_bertåº“ä¸fastaiå…¼å®¹ã€‚\n",
    "\n",
    "Dev Sharmaçš„æ–‡ç« ä½¿ç”¨RoBERTaä¸Fastaiåœ¨NLPä½¿pytorch_transformersåº“ä¸Fastaiå…¼å®¹ã€‚\n",
    "\n",
    "è™½ç„¶è¿™äº›æ–‡ç« éƒ½æ˜¯é«˜è´¨é‡çš„ï¼Œæ³¨æ„ä»–ä»¬çš„æ¼”ç¤ºæ˜¯ä¸å…¼å®¹çš„æœ€åç‰ˆæœ¬çš„transformerã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é›†æˆtransformerä¸fastaiå¤šåˆ†ç±»**\n",
    "\n",
    "åœ¨å¼€å§‹å®ç°ä¹‹å‰ï¼Œè¯·æ³¨æ„ï¼Œå¯ä»¥é€šè¿‡å¤šç§ä¸åŒçš„æ–¹å¼åœ¨fastaiä¸­é›†æˆtransformerã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘å†³å®šå¸¦æ¥æœ€é€šç”¨ã€æœ€çµæ´»çš„ç®€å•è§£å†³æ–¹æ¡ˆã€‚æ›´å‡†ç¡®åœ°è¯´ï¼Œæˆ‘å°è¯•åœ¨ä¸¤ä¸ªåº“ä¸­è¿›è¡Œæœ€å°çš„ä¿®æ”¹ï¼ŒåŒæ—¶ä½¿å®ƒä»¬ä¸æœ€å¤§æ•°é‡çš„transformeræ¶æ„å…¼å®¹ã€‚\n",
    "\n",
    "è¯·æ³¨æ„ï¼Œé™¤äº†è¿™ä¸ªç¬”è®°æœ¬å’Œè¿™ç¯‡åª’ä½“æ–‡ç« ä¹‹å¤–ï¼Œæˆ‘è¿˜åœ¨æˆ‘çš„GitHub(TODO add link)ä¸Šå‘å¸ƒäº†å¦ä¸€ä¸ªç‰ˆæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e4b766de8315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# transformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobertaConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
