{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk\n",
    "import nltk\n",
    "\n",
    "#stop-words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_text_1=\"bitty bought a bit of butter\"\n",
    "sample_text_2=\"but the bit of butter was a bit bitter\"\n",
    "sample_text_3=\"so she bought some better butter to make the bitter butter better\"\n",
    "\n",
    "corp=[sample_text_1,sample_text_2,sample_text_3]\n",
    "no_docs=len(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for document 1  is :  [45, 10, 30, 41, 14, 34]\n",
      "The encoding for document 2  is :  [17, 13, 41, 14, 34, 21, 30, 41, 22]\n",
      "The encoding for document 3  is :  [24, 4, 10, 45, 46, 34, 8, 4, 13, 22, 34, 46]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=50 \n",
    "encod_corp=[]\n",
    "for i,doc in enumerate(corp):\n",
    "    encod_corp.append(one_hot(doc,50))\n",
    "    print(\"The encoding for document\",i+1,\" is : \",one_hot(doc,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of words in any document is :  12\n"
     ]
    }
   ],
   "source": [
    "maxlen=-1\n",
    "for doc in corp:\n",
    "    tokens=nltk.word_tokenize(doc)\n",
    "    if(maxlen<len(tokens)):\n",
    "        maxlen=len(tokens)\n",
    "print(\"The maximum number of words in any document is : \",maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of padded documents:  3\n"
     ]
    }
   ],
   "source": [
    "# now to create embeddings all of our docs need to be of same length. hence we can pad the docs with zeros.\n",
    "pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='post',value=0.0)\n",
    "print(\"No of padded documents: \",len(pad_corp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padded encoding for document 1  is :  [45 10 30 41 14 34  0  0  0  0  0  0]\n",
      "The padded encoding for document 2  is :  [17 13 41 14 34 21 30 41 22  0  0  0]\n",
      "The padded encoding for document 3  is :  [24  4 10 45 46 34  8  4 13 22 34 46]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(pad_corp):\n",
    "     print(\"The padded encoding for document\",i+1,\" is : \",doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specifying the input shape\n",
    "input=Input(shape=(no_docs,maxlen),dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nshape of input. \\neach document has 12 element or words which is the value of our maxlen variable.\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "shape of input. \n",
    "each document has 12 element or words which is the value of our maxlen variable.\n",
    "\n",
    "'''\n",
    "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
    "\n",
    "# creating the embedding\n",
    "word_embedding=Embedding(input_dim=vocab_size,output_dim=8,input_length=maxlen)(word_input)\n",
    "\n",
    "word_vec=Flatten()(word_embedding) # flatten\n",
    "embed_model =Model([word_input],word_vec) # combining all into a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),loss='binary_crossentropy',metrics=['acc']) \n",
    "# compiling the model. parameters can be tuned as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(?, 12, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 12, 8)             400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embed_model.summary()) # summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dongy\\Anaconda3\\envs\\env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings=embed_model.predict(pad_corp) # finally getting the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 96)\n",
      "[[-0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574  0.01387862\n",
      "   0.01306662  0.02715177 -0.02688781  0.02109814 -0.00466151 -0.04597318\n",
      "  -0.04593098 -0.01970681  0.00707368  0.04694458 -0.01870829  0.03552436\n",
      "  -0.0456105  -0.00230848 -0.04606737 -0.00733572  0.02697546 -0.0380674\n",
      "  -0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012 -0.02591311\n",
      "   0.04654991  0.0150856  -0.00275113 -0.01618331 -0.00174323 -0.027293\n",
      "   0.04865906  0.04321125  0.00504465 -0.03549979 -0.00733699  0.01378724\n",
      "   0.01717141  0.0188974   0.03243555  0.0045498  -0.04819179 -0.03433678\n",
      "   0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "   0.04568959 -0.02697194  0.04971239 -0.0002454  -0.04866038 -0.02172011\n",
      "   0.04668837  0.04231835  0.04568959 -0.02697194  0.04971239 -0.0002454\n",
      "  -0.04866038 -0.02172011  0.04668837  0.04231835  0.04568959 -0.02697194\n",
      "   0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "   0.04568959 -0.02697194  0.04971239 -0.0002454  -0.04866038 -0.02172011\n",
      "   0.04668837  0.04231835  0.04568959 -0.02697194  0.04971239 -0.0002454\n",
      "  -0.04866038 -0.02172011  0.04668837  0.04231835  0.04568959 -0.02697194]\n",
      " [ 0.02032771  0.04646513 -0.01499258  0.03765203  0.02991349  0.00058996\n",
      "  -0.04678405 -0.00707883  0.04181578  0.04930561 -0.02573583 -0.03932854\n",
      "   0.03131188 -0.00456449  0.04988078 -0.02157731 -0.00057902 -0.01489658\n",
      "  -0.02773886  0.00620048 -0.04539012 -0.02591311  0.04654991  0.0150856\n",
      "  -0.00275113 -0.01618331 -0.00174323 -0.027293    0.04865906  0.04321125\n",
      "   0.00504465 -0.03549979 -0.00733699  0.01378724  0.01717141  0.0188974\n",
      "   0.03243555  0.0045498  -0.04819179 -0.03433678  0.00456911 -0.01514203\n",
      "  -0.0014233   0.02997683  0.01903645 -0.03845942  0.01625036 -0.0121733\n",
      "  -0.01870829  0.03552436 -0.0456105  -0.00230848 -0.04606737 -0.00733572\n",
      "   0.02697546 -0.0380674  -0.00057902 -0.01489658 -0.02773886  0.00620048\n",
      "  -0.04539012 -0.02591311  0.04654991  0.0150856   0.04914086  0.03331205\n",
      "   0.04123435  0.0436517  -0.02540605  0.01953856 -0.03322016 -0.04319388\n",
      "   0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "   0.04568959 -0.02697194  0.04971239 -0.0002454  -0.04866038 -0.02172011\n",
      "   0.04668837  0.04231835  0.04568959 -0.02697194  0.04971239 -0.0002454\n",
      "  -0.04866038 -0.02172011  0.04668837  0.04231835  0.04568959 -0.02697194]\n",
      " [ 0.01992954 -0.03849826  0.02040086  0.03205401 -0.00998838  0.02455393\n",
      "   0.03512121 -0.00362436  0.01773994 -0.04090065 -0.03787826  0.03548569\n",
      "   0.04924807 -0.04751766 -0.00241903  0.03145946 -0.02688781  0.02109814\n",
      "  -0.00466151 -0.04597318 -0.04593098 -0.01970681  0.00707368  0.04694458\n",
      "  -0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574  0.01387862\n",
      "   0.01306662  0.02715177  0.03990108  0.00698596 -0.04076189  0.03785687\n",
      "   0.04863025 -0.00580026 -0.04839167  0.02853889 -0.00733699  0.01378724\n",
      "   0.01717141  0.0188974   0.03243555  0.0045498  -0.04819179 -0.03433678\n",
      "   0.03613317 -0.0032151   0.00316951 -0.02114245 -0.01985568  0.00646915\n",
      "   0.01624812  0.02512074  0.01773994 -0.04090065 -0.03787826  0.03548569\n",
      "   0.04924807 -0.04751766 -0.00241903  0.03145946  0.04181578  0.04930561\n",
      "  -0.02573583 -0.03932854  0.03131188 -0.00456449  0.04988078 -0.02157731\n",
      "   0.04914086  0.03331205  0.04123435  0.0436517  -0.02540605  0.01953856\n",
      "  -0.03322016 -0.04319388 -0.00733699  0.01378724  0.01717141  0.0188974\n",
      "   0.03243555  0.0045498  -0.04819179 -0.03433678  0.03990108  0.00698596\n",
      "  -0.04076189  0.03785687  0.04863025 -0.00580026 -0.04839167  0.02853889]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of embeddings : \",embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 12, 8)\n",
      "[[[-0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574\n",
      "    0.01387862  0.01306662  0.02715177]\n",
      "  [-0.02688781  0.02109814 -0.00466151 -0.04597318 -0.04593098\n",
      "   -0.01970681  0.00707368  0.04694458]\n",
      "  [-0.01870829  0.03552436 -0.0456105  -0.00230848 -0.04606737\n",
      "   -0.00733572  0.02697546 -0.0380674 ]\n",
      "  [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012\n",
      "   -0.02591311  0.04654991  0.0150856 ]\n",
      "  [-0.00275113 -0.01618331 -0.00174323 -0.027293    0.04865906\n",
      "    0.04321125  0.00504465 -0.03549979]\n",
      "  [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555\n",
      "    0.0045498  -0.04819179 -0.03433678]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]]\n",
      "\n",
      " [[ 0.02032771  0.04646513 -0.01499258  0.03765203  0.02991349\n",
      "    0.00058996 -0.04678405 -0.00707883]\n",
      "  [ 0.04181578  0.04930561 -0.02573583 -0.03932854  0.03131188\n",
      "   -0.00456449  0.04988078 -0.02157731]\n",
      "  [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012\n",
      "   -0.02591311  0.04654991  0.0150856 ]\n",
      "  [-0.00275113 -0.01618331 -0.00174323 -0.027293    0.04865906\n",
      "    0.04321125  0.00504465 -0.03549979]\n",
      "  [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555\n",
      "    0.0045498  -0.04819179 -0.03433678]\n",
      "  [ 0.00456911 -0.01514203 -0.0014233   0.02997683  0.01903645\n",
      "   -0.03845942  0.01625036 -0.0121733 ]\n",
      "  [-0.01870829  0.03552436 -0.0456105  -0.00230848 -0.04606737\n",
      "   -0.00733572  0.02697546 -0.0380674 ]\n",
      "  [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012\n",
      "   -0.02591311  0.04654991  0.0150856 ]\n",
      "  [ 0.04914086  0.03331205  0.04123435  0.0436517  -0.02540605\n",
      "    0.01953856 -0.03322016 -0.04319388]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]\n",
      "  [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837\n",
      "    0.04231835  0.04568959 -0.02697194]]\n",
      "\n",
      " [[ 0.01992954 -0.03849826  0.02040086  0.03205401 -0.00998838\n",
      "    0.02455393  0.03512121 -0.00362436]\n",
      "  [ 0.01773994 -0.04090065 -0.03787826  0.03548569  0.04924807\n",
      "   -0.04751766 -0.00241903  0.03145946]\n",
      "  [-0.02688781  0.02109814 -0.00466151 -0.04597318 -0.04593098\n",
      "   -0.01970681  0.00707368  0.04694458]\n",
      "  [-0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574\n",
      "    0.01387862  0.01306662  0.02715177]\n",
      "  [ 0.03990108  0.00698596 -0.04076189  0.03785687  0.04863025\n",
      "   -0.00580026 -0.04839167  0.02853889]\n",
      "  [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555\n",
      "    0.0045498  -0.04819179 -0.03433678]\n",
      "  [ 0.03613317 -0.0032151   0.00316951 -0.02114245 -0.01985568\n",
      "    0.00646915  0.01624812  0.02512074]\n",
      "  [ 0.01773994 -0.04090065 -0.03787826  0.03548569  0.04924807\n",
      "   -0.04751766 -0.00241903  0.03145946]\n",
      "  [ 0.04181578  0.04930561 -0.02573583 -0.03932854  0.03131188\n",
      "   -0.00456449  0.04988078 -0.02157731]\n",
      "  [ 0.04914086  0.03331205  0.04123435  0.0436517  -0.02540605\n",
      "    0.01953856 -0.03322016 -0.04319388]\n",
      "  [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555\n",
      "    0.0045498  -0.04819179 -0.03433678]\n",
      "  [ 0.03990108  0.00698596 -0.04076189  0.03785687  0.04863025\n",
      "   -0.00580026 -0.04839167  0.02853889]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings=embeddings.reshape(-1,maxlen,8)\n",
    "print(\"Shape of embeddings : \",embeddings.shape) \n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for  1 th word in 1 th document is : \n",
      "\n",
      " [-0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574  0.01387862\n",
      "  0.01306662  0.02715177]\n",
      "The encoding for  2 th word in 1 th document is : \n",
      "\n",
      " [-0.02688781  0.02109814 -0.00466151 -0.04597318 -0.04593098 -0.01970681\n",
      "  0.00707368  0.04694458]\n",
      "The encoding for  3 th word in 1 th document is : \n",
      "\n",
      " [-0.01870829  0.03552436 -0.0456105  -0.00230848 -0.04606737 -0.00733572\n",
      "  0.02697546 -0.0380674 ]\n",
      "The encoding for  4 th word in 1 th document is : \n",
      "\n",
      " [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012 -0.02591311\n",
      "  0.04654991  0.0150856 ]\n",
      "The encoding for  5 th word in 1 th document is : \n",
      "\n",
      " [-0.00275113 -0.01618331 -0.00174323 -0.027293    0.04865906  0.04321125\n",
      "  0.00504465 -0.03549979]\n",
      "The encoding for  6 th word in 1 th document is : \n",
      "\n",
      " [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555  0.0045498\n",
      " -0.04819179 -0.03433678]\n",
      "The encoding for  7 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  8 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  9 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  10 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  11 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  12 th word in 1 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  1 th word in 2 th document is : \n",
      "\n",
      " [ 0.02032771  0.04646513 -0.01499258  0.03765203  0.02991349  0.00058996\n",
      " -0.04678405 -0.00707883]\n",
      "The encoding for  2 th word in 2 th document is : \n",
      "\n",
      " [ 0.04181578  0.04930561 -0.02573583 -0.03932854  0.03131188 -0.00456449\n",
      "  0.04988078 -0.02157731]\n",
      "The encoding for  3 th word in 2 th document is : \n",
      "\n",
      " [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012 -0.02591311\n",
      "  0.04654991  0.0150856 ]\n",
      "The encoding for  4 th word in 2 th document is : \n",
      "\n",
      " [-0.00275113 -0.01618331 -0.00174323 -0.027293    0.04865906  0.04321125\n",
      "  0.00504465 -0.03549979]\n",
      "The encoding for  5 th word in 2 th document is : \n",
      "\n",
      " [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555  0.0045498\n",
      " -0.04819179 -0.03433678]\n",
      "The encoding for  6 th word in 2 th document is : \n",
      "\n",
      " [ 0.00456911 -0.01514203 -0.0014233   0.02997683  0.01903645 -0.03845942\n",
      "  0.01625036 -0.0121733 ]\n",
      "The encoding for  7 th word in 2 th document is : \n",
      "\n",
      " [-0.01870829  0.03552436 -0.0456105  -0.00230848 -0.04606737 -0.00733572\n",
      "  0.02697546 -0.0380674 ]\n",
      "The encoding for  8 th word in 2 th document is : \n",
      "\n",
      " [-0.00057902 -0.01489658 -0.02773886  0.00620048 -0.04539012 -0.02591311\n",
      "  0.04654991  0.0150856 ]\n",
      "The encoding for  9 th word in 2 th document is : \n",
      "\n",
      " [ 0.04914086  0.03331205  0.04123435  0.0436517  -0.02540605  0.01953856\n",
      " -0.03322016 -0.04319388]\n",
      "The encoding for  10 th word in 2 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  11 th word in 2 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  12 th word in 2 th document is : \n",
      "\n",
      " [ 0.04971239 -0.0002454  -0.04866038 -0.02172011  0.04668837  0.04231835\n",
      "  0.04568959 -0.02697194]\n",
      "The encoding for  1 th word in 3 th document is : \n",
      "\n",
      " [ 0.01992954 -0.03849826  0.02040086  0.03205401 -0.00998838  0.02455393\n",
      "  0.03512121 -0.00362436]\n",
      "The encoding for  2 th word in 3 th document is : \n",
      "\n",
      " [ 0.01773994 -0.04090065 -0.03787826  0.03548569  0.04924807 -0.04751766\n",
      " -0.00241903  0.03145946]\n",
      "The encoding for  3 th word in 3 th document is : \n",
      "\n",
      " [-0.02688781  0.02109814 -0.00466151 -0.04597318 -0.04593098 -0.01970681\n",
      "  0.00707368  0.04694458]\n",
      "The encoding for  4 th word in 3 th document is : \n",
      "\n",
      " [-0.0260285  -0.02942736 -0.0190503   0.01000122 -0.04945574  0.01387862\n",
      "  0.01306662  0.02715177]\n",
      "The encoding for  5 th word in 3 th document is : \n",
      "\n",
      " [ 0.03990108  0.00698596 -0.04076189  0.03785687  0.04863025 -0.00580026\n",
      " -0.04839167  0.02853889]\n",
      "The encoding for  6 th word in 3 th document is : \n",
      "\n",
      " [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555  0.0045498\n",
      " -0.04819179 -0.03433678]\n",
      "The encoding for  7 th word in 3 th document is : \n",
      "\n",
      " [ 0.03613317 -0.0032151   0.00316951 -0.02114245 -0.01985568  0.00646915\n",
      "  0.01624812  0.02512074]\n",
      "The encoding for  8 th word in 3 th document is : \n",
      "\n",
      " [ 0.01773994 -0.04090065 -0.03787826  0.03548569  0.04924807 -0.04751766\n",
      " -0.00241903  0.03145946]\n",
      "The encoding for  9 th word in 3 th document is : \n",
      "\n",
      " [ 0.04181578  0.04930561 -0.02573583 -0.03932854  0.03131188 -0.00456449\n",
      "  0.04988078 -0.02157731]\n",
      "The encoding for  10 th word in 3 th document is : \n",
      "\n",
      " [ 0.04914086  0.03331205  0.04123435  0.0436517  -0.02540605  0.01953856\n",
      " -0.03322016 -0.04319388]\n",
      "The encoding for  11 th word in 3 th document is : \n",
      "\n",
      " [-0.00733699  0.01378724  0.01717141  0.0188974   0.03243555  0.0045498\n",
      " -0.04819179 -0.03433678]\n",
      "The encoding for  12 th word in 3 th document is : \n",
      "\n",
      " [ 0.03990108  0.00698596 -0.04076189  0.03785687  0.04863025 -0.00580026\n",
      " -0.04839167  0.02853889]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(embeddings):\n",
    "    for j,word in enumerate(doc):\n",
    "        print(\"The encoding for \",j+1,\"th word\",\"in\",i+1,\"th document is : \\n\\n\",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
