{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 基于word counts特征，使用xgboost："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7265 entries, 0 to 7339\n",
      "Data columns (total 5 columns):\n",
      "id         7265 non-null object\n",
      "title      7265 non-null object\n",
      "content    7265 non-null object\n",
      "label      7265 non-null int64\n",
      "X          7265 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 340.5+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dongy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "#处理训练集，将训练集的文本信息和label信息合并，清洗特殊符号，同时将文本内容进行分词\n",
    "def merge_feature_label(feature_name,label_name):\n",
    "    feature=pd.read_csv(feature_name,sep=\",\")\n",
    "    label=pd.read_csv(label_name,sep=\",\")\n",
    "    data=feature.merge(label,on='id')\n",
    "    data[\"X\"]=data[[\"title\",\"content\"]].apply(lambda x:\"\".join([str(x[0]),str(x[1])]),axis=1)\n",
    "    # 丢掉缺失值\n",
    "    dataDropNa=data.dropna(axis=0, how='any')\n",
    "    print(dataDropNa.info())\n",
    "    dataDropNa[\"X\"]=dataDropNa[\"X\"].apply(lambda x: str(x).replace(\"\\\\n\",\"\").replace(\".\",\"\").replace(\"\\n\",\"\").replace(\"　\",\"\").replace(\"↓\",\"\").replace(\"/\",\"\").replace(\"|\",\"\").replace(\" \",\"\"))\n",
    "    dataDropNa[\"X_split\"]=dataDropNa[\"X\"].apply(lambda x:\" \".join(jieba.cut(x)))\n",
    "    return dataDropNa\n",
    " \n",
    "dataDropNa=merge_feature_label(\"Train_DataSet.csv\",\"Train_DataSet_Label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7356 entries, 0 to 7355\n",
      "Data columns (total 4 columns):\n",
      "id         7356 non-null object\n",
      "title      7356 non-null object\n",
      "content    7288 non-null object\n",
      "X          7356 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 230.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#处理测试数据\n",
    "def process_test(test_name):\n",
    "    test=pd.read_csv(test_name,sep=\",\")\n",
    "    # apply()方法能劫持另外一个对象的方法，继承另外一个对象的属性 \n",
    "    # lambda https://blog.csdn.net/zjuxsl/article/details/79437563\n",
    "    #  join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。\n",
    "    test[\"X\"]=test[[\"title\",\"content\"]].apply(lambda x:\"\".join([str(x[0]),str(x[1])]),axis=1)\n",
    "    # 列名信息\n",
    "    print(test.info())\n",
    "    # replace(old, new) 方法把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。\n",
    "    test[\"X\"]=test[\"X\"].apply(lambda x: str(x).replace(\"\\\\n\",\"\").replace(\".\",\"\").replace(\"\\n\",\"\").replace(\"　\",\"\").replace(\"↓\",\"\").replace(\"/\",\"\").replace(\"|\",\"\").replace(\" \",\"\"))\n",
    "    # jieba.cut()按照词性切分“我爱中国”切分成我爱中国\n",
    "    test[\"X_split\"]=test[\"X\"].apply(lambda x:\" \".join(jieba.cut(x)))\n",
    "    return test\n",
    " \n",
    "testData=process_test(\"Test_DataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = dataDropNa.X_split.values # 训练集文本分词数据\n",
    "train_y = dataDropNa.label.values # 训练集标签\n",
    "test_x = testData.X_split.values #测试集文本分词数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将数据分成训练和验证集。我们可以使用scikit-learn的model_selection模块中的train_test_split来完成它。\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_x, train_y,\n",
    "                                                  stratify=train_y, \n",
    "                                                  random_state=42,\n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过损失函数值来选择模型。\n",
    "def multiclass_logloss(actual, predicted, eps = 1e-15):\n",
    "    \"对数损失度量\"\n",
    "    \n",
    "    if len(actual.shape)==1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "        \n",
    "    clip = np.clip(predicted, eps, 1-eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6538,)\n",
      "(727,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain.shape) \n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用词汇计数(Word Counts)作为功能。可以使用scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 向量化\n",
    "ctv = CountVectorizer(min_df=3, \n",
    "                      max_df=0.5, \n",
    "                      ngram_range=(1,2)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Count Vectorizer来fit训练集中划分出来的的训练集文本分词数据xtrain和验证集文本分词数据xvalid，训练整个训练集文本分词数据train_x和测试集文本分词数据test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizer来fit训练集中划分出来的的训练集文本分词数据xtrain和验证集文本分词数据xvalid\n",
    "ctv.fit(list(xtrain) + list(xvalid)) \n",
    "xtrain_ctv = ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)\n",
    "\n",
    "\n",
    "# Vectorizer来fit训练整个训练集文本分词数据traindata和测试集文本分词数据testdata\n",
    "ctv.fit(list(train_x) + list(test_x)) \n",
    "train_x_ctv = ctv.transform(train_x)\n",
    "test_x_ctv = ctv.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用提取的word counts特征来fit一个简单的Logistic Regression ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.600 \n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1.0,solver='lbfgs',multi_class='multinomial') \n",
    "clf.fit(xtrain_ctv, ytrain) \n",
    "predictions = clf.predict_proba(xvalid_ctv) \n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果略差。。。\n",
    "\n",
    "接下来,尝试一个非常简单的模型- 朴素贝叶斯。\n",
    "\n",
    "利用提取的word counts特征来fitNaive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 6.870 \n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(xtrain_ctv, ytrain) \n",
    "predictions = clf.predict_proba(xvalid_ctv) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果不好。。。\n",
    "\n",
    "基于word counts特征，使用xgboost："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.590 \n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
    "\n",
    "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于word counts特征的xgboost模型logloss最小，选择此模型，再进行总的训练和测试\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(train_x_ctv.tocsc(), train_y)\n",
    "predictions = clf.predict_proba(test_x_ctv.tocsc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4990451 ,  0.48234281,  0.01861211],\n",
       "       [ 0.09148925,  0.46422803,  0.44428271],\n",
       "       [ 0.00578942,  0.84613031,  0.14808029],\n",
       "       ..., \n",
       "       [ 0.11486442,  0.88370866,  0.00142692],\n",
       "       [ 0.16532095,  0.82567328,  0.00900571],\n",
       "       [ 0.07465193,  0.91159981,  0.01374823]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7356, 1)\n"
     ]
    }
   ],
   "source": [
    "preds=np.argmax(predictions,axis=1)\n",
    "test_pred=pd.DataFrame(preds)\n",
    "test_pred.columns=[\"label\"]\n",
    "print(test_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred[\"id\"]=list(testData[\"id\"])\n",
    "test_pred[[\"id\",\"label\"]].to_csv('word_counts_xgboost.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
